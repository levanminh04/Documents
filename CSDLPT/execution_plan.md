# ğŸ» Káº¾ HOáº CH THá»°C THI CHI TIáº¾T â€” PHÆ¯Æ NG ÃN B (FULL PYTHON)
## NhÃ³m 3 ngÆ°á»i Â· 12 tuáº§n Â· Budget 0Ä‘

---

# 1. PHÃ‚N CÃ”NG VAI TRÃ’ NHÃ“M (3 NGÆ¯á»œI)

| Vai trÃ² | KÃ½ hiá»‡u | TrÃ¡ch nhiá»‡m chÃ­nh | Ká»¹ nÄƒng cáº§n |
|---------|---------|-------------------|-------------|
| **Tech Lead + Backend** | **TL** | Kiáº¿n trÃºc há»‡ thá»‘ng, FastAPI, PostgreSQL, pgvector, deployment | Python trung bÃ¬nh+, SQL |
| **Audio/Data Engineer** | **AE** | Thu tháº­p dá»¯ liá»‡u, feature extraction pipeline, normalization, testing cháº¥t lÆ°á»£ng audio | Python cÆ¡ báº£n, chá»‹u khÃ³ research |
| **Frontend + QA + Docs** | **FQ** | Giao diá»‡n web (HTML/CSS/JS), viáº¿t bÃ¡o cÃ¡o, test thá»§ cÃ´ng, chuáº©n bá»‹ demo | HTML/CSS, viáº¿t tá»‘t |

> [!IMPORTANT]
> **NguyÃªn táº¯c vÃ ng cho nhÃ³m 3 ngÆ°á»i:** KhÃ´ng ai Ä‘Æ°á»£c lÃ m viá»‡c cÃ´ láº­p quÃ¡ 2 tuáº§n. Má»—i Chá»§ Nháº­t tá»‘i cÃ³ standup 15 phÃºt (Zalo/Discord call) Ä‘á»ƒ sync tiáº¿n Ä‘á»™. Náº¿u 1 ngÆ°á»i stuck â†’ 2 ngÆ°á»i cÃ²n láº¡i pair-program há»— trá»£ ngay.

---

# 2. PROJECT STRUCTURE (Táº¡o tá»« ngÃ y Ä‘áº§u)

```
string-instrument-search/
â”œâ”€â”€ README.md                    # HÆ°á»›ng dáº«n setup + cháº¡y
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ .env.example                 # Template biáº¿n mÃ´i trÆ°á»ng
â”œâ”€â”€ start.bat                    # 1-click cháº¡y server (Windows)
â”‚
â”œâ”€â”€ app/                         # FastAPI application
â”‚   â”œâ”€â”€ main.py                  # Entry point, CORS, mount static
â”‚   â”œâ”€â”€ config.py                # DB URL, paths, constants
â”‚   â”œâ”€â”€ database.py              # SQLAlchemy engine + session
â”‚   â”œâ”€â”€ models.py                # ORM models (instruments, audio_features)
â”‚   â”œâ”€â”€ schemas.py               # Pydantic request/response schemas
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ search.py            # POST /api/search
â”‚   â”‚   â”œâ”€â”€ instruments.py       # GET /api/instruments
â”‚   â”‚   â””â”€â”€ visualize.py         # GET /api/visualize/{id}
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ feature_extractor.py # librosa feature extraction
â”‚       â”œâ”€â”€ similarity.py        # pgvector query logic
â”‚       â””â”€â”€ visualizer.py        # matplotlib spectrogram/waveform
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ seed_database.py         # Batch: Ä‘á»c data/ â†’ extract â†’ insert DB
â”‚   â”œâ”€â”€ download_nsynth.py       # Download & filter NSynth dataset
â”‚   â”œâ”€â”€ normalize_audio.py       # Convert táº¥t cáº£ vá» wav 22050Hz mono
â”‚   â””â”€â”€ validate_data.py         # Kiá»ƒm tra cháº¥t lÆ°á»£ng dataset
â”‚
â”œâ”€â”€ templates/                   # Jinja2 HTML templates
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ index.html               # Trang upload + search
â”‚   â”œâ”€â”€ results.html             # Hiá»ƒn thá»‹ top-5 results
â”‚   â””â”€â”€ browse.html              # Duyá»‡t database
â”‚
â”œâ”€â”€ static/                      # CSS, JS, images
â”‚   â”œâ”€â”€ css/style.css
â”‚   â”œâ”€â”€ js/app.js
â”‚   â””â”€â”€ visualizations/          # Spectrogram images (generated)
â”‚
â”œâ”€â”€ data/                        # Audio files (KHÃ”NG push lÃªn Git)
â”‚   â”œâ”€â”€ violin/
â”‚   â”œâ”€â”€ guitar/
â”‚   â”œâ”€â”€ cello/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_feature_extractor.py
â”‚   â””â”€â”€ test_search.py
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ report.docx              # BÃ¡o cÃ¡o cuá»‘i ká»³
    â””â”€â”€ slides.pptx              # Slide demo
```

---

# 3. TIMELINE CHI TIáº¾T â€” 6 PHASE

```mermaid
gantt
    title Execution Timeline â€” 3 ngÆ°á»i, 12 tuáº§n
    dateFormat YYYY-MM-DD
    axisFormat %d/%m

    section Phase 0 Â· Setup
    CÃ i Ä‘áº·t + Há»c FastAPI cÆ¡ báº£n     :p0, 2026-02-24, 14d

    section Phase 1 Â· Data
    Thu tháº­p & chuáº©n hÃ³a 500+ files  :p1, after p0, 14d

    section Phase 2 Â· Engine
    Feature extraction + DB seeding   :crit, p2, after p1, 14d

    section Phase 3 Â· API
    Search API + Similarity logic     :p3, after p2, 14d

    section Phase 4 Â· UI
    Web UI + Visualization            :p4, after p3, 14d

    section Phase 5 Â· Demo
    Polish + BÃ¡o cÃ¡o + Demo prep      :p5, after p4, 14d
```

---

## PHASE 0: SETUP & ONBOARDING (Tuáº§n 1â€“2) `24/02 â†’ 09/03`

**Má»¥c tiÃªu:** Cáº£ nhÃ³m cháº¡y Ä‘Æ°á»£c "Hello World" FastAPI + káº¿t ná»‘i PostgreSQL.

### Tuáº§n 1 â€” CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

| Task | Ai | Chi tiáº¿t | Thá»i gian |
|------|----|----------|-----------|
| CÃ i Python 3.11 + pip + venv | Cáº£ 3 | Má»—i ngÆ°á»i tá»± cÃ i trÃªn mÃ¡y cÃ¡ nhÃ¢n | 1 giá» |
| CÃ i PostgreSQL 16 + pgvector | **TL** | CÃ i xong share guide cho 2 ngÆ°á»i cÃ²n láº¡i | 2 giá» |
| Táº¡o Git repo + project structure | **TL** | Theo cáº¥u trÃºc á»Ÿ trÃªn, push lÃªn GitHub | 1 giá» |
| CÃ i VS Code + Python extension | Cáº£ 3 | Extensions: Python, Pylance, SQLTools | 30 phÃºt |
| Viáº¿t `requirements.txt` ban Ä‘áº§u | **TL** | `fastapi, uvicorn, sqlalchemy, pgvector, librosa, numpy, matplotlib, python-multipart, jinja2` | 30 phÃºt |

### Tuáº§n 2 â€” Há»c FastAPI cÆ¡ báº£n

| Task | Ai | Chi tiáº¿t | Thá»i gian |
|------|----|----------|-----------|
| Tutorial FastAPI (docs chÃ­nh thá»©c) | **TL**, **AE** | Táº¡o Ä‘Æ°á»£c endpoint GET/POST, return JSON | 4 giá» má»—i ngÆ°á»i |
| Tutorial librosa cÆ¡ báº£n | **AE** | Load 1 file .wav, extract MFCC, in ra | 3 giá» |
| Há»c HTML/CSS cÆ¡ báº£n + Jinja2 | **FQ** | Render template tá»« FastAPI, form upload | 4 giá» |
| Test pgvector: insert + query vector | **TL** | Cháº¡y Ä‘Æ°á»£c `SELECT embedding <=> '[1,2,3]'::vector` | 2 giá» |

**âœ… Checkpoint cuá»‘i Phase 0:**
- [ ] `uvicorn app.main:app --reload` cháº¡y Ä‘Æ°á»£c trÃªn cáº£ 3 mÃ¡y
- [ ] Endpoint `GET /health` tráº£ vá» `{"status": "ok"}`
- [ ] PostgreSQL káº¿t ná»‘i Ä‘Æ°á»£c, pgvector extension enabled
- [ ] **AE** load Ä‘Æ°á»£c 1 file .wav báº±ng librosa, in ra MFCC values

---

## PHASE 1: THU THáº¬P & CHUáº¨N HÃ“A Dá»® LIá»†U (Tuáº§n 3â€“4) `10/03 â†’ 23/03`

**Má»¥c tiÃªu:** CÃ³ thÆ° má»¥c `data/` chá»©a 500+ files .wav Ä‘Ã£ phÃ¢n loáº¡i, kÃ¨m `metadata.csv`.

### Nguá»“n dá»¯ liá»‡u (Æ°u tiÃªn theo thá»© tá»±)

| # | Nguá»“n | Nháº¡c cá»¥ cÃ³ | Sá»‘ lÆ°á»£ng Æ°á»›c tÃ­nh | CÃ¡ch láº¥y |
|---|-------|-----------|-------------------|----------|
| 1 | **NSynth Dataset** (Google Magenta) | Guitar, Violin, Cello, Bass, Harp | 400+ files (filter acoustic + string) | Download tá»« [NSynth](https://magenta.tensorflow.org/datasets/nsynth), filter JSON metadata |
| 2 | **IRMAS Dataset** | Guitar, Violin, Cello | 100+ files | Download tá»« [IRMAS](https://www.upf.edu/web/mtg/irmas) |
| 3 | **Freesound.org** | ÄÃ n tranh, ÄÃ n báº§u, Banjo, Ukulele, Mandolin | 50+ files bá»• sung | Search thá»§ cÃ´ng, chá»n file CC license |
| 4 | **Philharmonia Orchestra** | Violin, Viola, Cello, Double Bass, Harp | 200+ files (single notes) | Download tá»« [philharmonia.co.uk/explore/sound_samples](https://philharmonia.co.uk/explore/sound_samples) |

### Nháº¡c cá»¥ bá»™ dÃ¢y má»¥c tiÃªu (tá»‘i thiá»ƒu 5 loáº¡i)

| Nháº¡c cá»¥ | PhÃ¢n loáº¡i | Target files |
|---------|-----------|-------------|
| ğŸ» Violin | Bowed string | 100+ |
| ğŸ» Viola | Bowed string | 50+ |
| ğŸ» Cello | Bowed string | 100+ |
| ğŸ¸ Acoustic Guitar | Plucked string | 100+ |
| ğŸª• Bass (Double Bass / Electric Bass) | Bowed/Plucked | 80+ |
| ğŸµ Harp | Plucked string | 50+ |
| ğŸª• Banjo / Ukulele / Others | Plucked string | 20+ (bonus) |

### PhÃ¢n cÃ´ng Phase 1

| Task | Ai | Chi tiáº¿t | Deadline |
|------|----|----------|----------|
| Download + filter NSynth | **AE** | Viáº¿t `scripts/download_nsynth.py`: download, parse JSON metadata, filter `instrument_family="string"` + `instrument_source="acoustic"`, copy files | Cuá»‘i tuáº§n 3 |
| Download IRMAS + Philharmonia | **FQ** | Download thá»§ cÃ´ng, phÃ¢n loáº¡i vÃ o thÆ° má»¥c Ä‘Ãºng | Cuá»‘i tuáº§n 3 |
| Bá»• sung tá»« Freesound | **FQ** | Search + download, Ä‘áº£m báº£o license CC | Tuáº§n 4 |
| Viáº¿t script chuáº©n hÃ³a audio | **AE** | `scripts/normalize_audio.py`: convert táº¥t cáº£ â†’ `.wav`, 22050Hz, mono, trim silence | Tuáº§n 4 |
| Táº¡o `metadata.csv` | **AE** + **FQ** | Columns: `file_path, instrument_name, note, duration_sec, sample_rate, source` | Cuá»‘i tuáº§n 4 |
| Validate dataset | **TL** | `scripts/validate_data.py`: Ä‘áº¿m files, check duration > 1s, check khÃ´ng corrupt | Cuá»‘i tuáº§n 4 |

**Script chuáº©n hÃ³a máº«u:**
```python
# scripts/normalize_audio.py
import librosa
import soundfile as sf
import os
from pathlib import Path

def normalize_audio(input_dir: str, output_dir: str, target_sr: int = 22050):
    """Convert táº¥t cáº£ audio files sang wav, 22050Hz, mono."""
    for root, dirs, files in os.walk(input_dir):
        for f in files:
            if f.endswith(('.wav', '.mp3', '.flac', '.ogg', '.aiff')):
                input_path = os.path.join(root, f)
                # Giá»¯ nguyÃªn cáº¥u trÃºc thÆ° má»¥c
                rel_path = os.path.relpath(root, input_dir)
                out_dir = os.path.join(output_dir, rel_path)
                os.makedirs(out_dir, exist_ok=True)
                
                out_path = os.path.join(out_dir, Path(f).stem + '.wav')
                
                try:
                    y, sr = librosa.load(input_path, sr=target_sr, mono=True)
                    # Trim silence Ä‘áº§u/cuá»‘i
                    y_trimmed, _ = librosa.effects.trim(y, top_db=20)
                    sf.write(out_path, y_trimmed, target_sr)
                    print(f"âœ“ {input_path} â†’ {out_path} ({len(y_trimmed)/target_sr:.1f}s)")
                except Exception as e:
                    print(f"âœ— SKIP {input_path}: {e}")
```

**âœ… Checkpoint cuá»‘i Phase 1:**
- [ ] ThÆ° má»¥c `data/` cÃ³ 500+ files `.wav`
- [ ] Má»—i nháº¡c cá»¥ cÃ³ Ã­t nháº¥t 50 files
- [ ] `metadata.csv` Ä‘áº§y Ä‘á»§, khÃ´ng cÃ³ dÃ²ng lá»—i
- [ ] Táº¥t cáº£ files: mono, 22050Hz, duration 1-10 giÃ¢y

---

## PHASE 2: CORE ENGINE â€” Feature Extraction + DB (Tuáº§n 5â€“6) `24/03 â†’ 06/04`

> [!CAUTION]
> **ğŸ”´ CRITICAL PATH â€” Phase quan trá»ng nháº¥t cáº£ dá»± Ã¡n.** Náº¿u feature extraction sai â†’ similarity search vÃ´ nghÄ©a â†’ báº£o vá»‡ fail. Pháº£i test ká»¹.

### PhÃ¢n cÃ´ng Phase 2

| Task | Ai | Chi tiáº¿t | Deadline |
|------|----|----------|----------|
| Implement `feature_extractor.py` | **AE** + **TL** (pair) | HÃ m `extract_features(file_path) â†’ np.ndarray[30]`. **Pair programming báº¯t buá»™c cho task nÃ y.** | Giá»¯a tuáº§n 5 |
| Unit tests cho feature extractor | **AE** | Test vá»›i 5-10 files: verify output shape = (30,), giÃ¡ trá»‹ trong range há»£p lÃ½ | Cuá»‘i tuáº§n 5 |
| Táº¡o DB schema (migration script) | **TL** | DDL script táº¡o tables + pgvector index | Tuáº§n 5 |
| ORM models (SQLAlchemy) | **TL** | `models.py`: `Instrument`, `AudioFeature` classes | Tuáº§n 5 |
| Batch seeding script | **TL** + **AE** | `scripts/seed_database.py`: Ä‘á»c 500 files â†’ extract features â†’ normalize â†’ insert | Tuáº§n 6 |
| Sanity check | Cáº£ 3 | Query: upload guitar â†’ top-5 pháº£i chá»§ yáº¿u guitar. Náº¿u khÃ´ng â†’ debug | Cuá»‘i tuáº§n 6 |
| NghiÃªn cá»©u UI mockup | **FQ** | Váº½ wireframe trÃªn giáº¥y / Figma cho trang Search + Results | Song song tuáº§n 5-6 |

### Feature Extraction â€” Code Ä‘áº§y Ä‘á»§

```python
# app/services/feature_extractor.py
import librosa
import numpy as np
from typing import Dict, Any

def extract_features(file_path: str, sr: int = 22050) -> Dict[str, Any]:
    """
    TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng Ã¢m thanh tá»« file.
    Returns dict chá»©a:
      - feature_vector: np.ndarray shape (30,) â€” dÃ¹ng cho similarity search
      - details: dict cÃ¡c giÃ¡ trá»‹ riÃªng láº» â€” dÃ¹ng cho hiá»ƒn thá»‹/debug
      - metadata: dict thÃ´ng tin file (duration, sr)
    """
    y, sr = librosa.load(file_path, sr=sr, mono=True)
    
    # === 1. MFCC (13 dims) â€” "Fingerprint" Ã¢m thanh ===
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    mfcc_mean = np.mean(mfcc, axis=1)      # (13,)
    
    # === 2. Chroma (12 dims) â€” Pitch / ná»‘t nháº¡c ===
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    chroma_mean = np.mean(chroma, axis=1)   # (12,)
    
    # === 3. Spectral Features (5 dims) â€” Texture Ã¢m thanh ===
    centroid = float(np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)))
    bandwidth = float(np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)))
    rolloff = float(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))
    zcr = float(np.mean(librosa.feature.zero_crossing_rate(y)))
    rms = float(np.mean(librosa.feature.rms(y=y)))
    
    # === Concatenate â†’ vector 30 chiá»u ===
    feature_vector = np.concatenate([
        mfcc_mean,                              # 13
        chroma_mean,                            # 12
        [centroid, bandwidth, rolloff, zcr, rms] # 5
    ])
    
    return {
        "feature_vector": feature_vector,       # shape (30,)
        "details": {
            "mfcc_mean": mfcc_mean.tolist(),
            "chroma_mean": chroma_mean.tolist(),
            "spectral_centroid": centroid,
            "spectral_bandwidth": bandwidth,
            "spectral_rolloff": rolloff,
            "zero_crossing_rate": zcr,
            "rms_energy": rms,
        },
        "metadata": {
            "duration_sec": float(len(y) / sr),
            "sample_rate": sr,
        }
    }
```

### Normalization Strategy (QUAN TRá»ŒNG)

```python
# scripts/seed_database.py (pháº§n normalization)
import numpy as np
from sklearn.preprocessing import StandardScaler

def seed_database(data_dir: str, db_session):
    """Batch extract + normalize + insert."""
    # BÆ°á»›c 1: Extract features cho Táº¤T Cáº¢ files
    all_vectors = []
    all_records = []
    for file_path, instrument_name in iterate_dataset(data_dir):
        result = extract_features(file_path)
        all_vectors.append(result["feature_vector"])
        all_records.append((file_path, instrument_name, result))
    
    # BÆ°á»›c 2: Fit scaler trÃªn toÃ n dataset
    vectors_matrix = np.array(all_vectors)  # shape (N, 30)
    scaler = StandardScaler()
    normalized_vectors = scaler.fit_transform(vectors_matrix)
    
    # âš ï¸ LÆ¯U scaler Ä‘á»ƒ dÃ¹ng khi search (file query cÅ©ng pháº£i normalize cÃ¹ng scaler)
    import joblib
    joblib.dump(scaler, "models/scaler.pkl")
    
    # BÆ°á»›c 3: Insert vÃ o database
    for i, (file_path, instrument_name, result) in enumerate(all_records):
        norm_vector = normalized_vectors[i].tolist()
        insert_to_db(db_session, file_path, instrument_name, result, norm_vector)
    
    print(f"âœ… Seeded {len(all_records)} records. Scaler saved to models/scaler.pkl")
```

> [!WARNING]
> **Sai láº§m phá»• biáº¿n:** QuÃªn normalize vector query khi search. File upload tá»« user PHáº¢I Ä‘Æ°á»£c transform báº±ng **cÃ¹ng scaler** Ä‘Ã£ fit trÃªn dataset. Náº¿u khÃ´ng, khoáº£ng cÃ¡ch cosine sáº½ vÃ´ nghÄ©a.

### Sanity Check Script

```python
# scripts/sanity_check.py
"""Cháº¡y sau khi seed â†’ kiá»ƒm tra káº¿t quáº£ cÃ³ há»£p lÃ½ khÃ´ng."""

def sanity_check(db_session):
    # Láº¥y 1 file guitar báº¥t ká»³ trong DB
    guitar_sample = query_one_by_instrument(db_session, "guitar")
    
    # Search top-10
    results = search_similar(db_session, guitar_sample.embedding, limit=10)
    
    # Äáº¿m bao nhiÃªu káº¿t quáº£ cÅ©ng lÃ  guitar
    guitar_count = sum(1 for r in results if r.instrument_name == "guitar")
    
    print(f"Query: guitar â†’ Top-10 results: {guitar_count}/10 lÃ  guitar")
    
    if guitar_count >= 6:
        print("âœ… PASS â€” Features Ä‘ang hoáº¡t Ä‘á»™ng há»£p lÃ½")
    else:
        print("âŒ FAIL â€” Cáº§n debug feature extraction hoáº·c normalization")
        # In chi tiáº¿t Ä‘á»ƒ debug
        for r in results:
            print(f"  {r.instrument_name}: distance={r.distance:.4f}")
```

**âœ… Checkpoint cuá»‘i Phase 2:**
- [ ] `extract_features()` cháº¡y Ä‘Ãºng, output shape (30,)
- [ ] DB cÃ³ 500+ records, vector embedding normalized
- [ ] `scaler.pkl` Ä‘Ã£ Ä‘Æ°á»£c save
- [ ] Sanity check PASS: query guitar â†’ â‰¥6/10 top results lÃ  guitar
- [ ] Sanity check PASS: query violin â†’ â‰¥6/10 top results lÃ  violin

---

## PHASE 3: SEARCH API (Tuáº§n 7â€“8) `07/04 â†’ 20/04`

### PhÃ¢n cÃ´ng Phase 3

| Task | Ai | Chi tiáº¿t | Deadline |
|------|----|----------|----------|
| `POST /api/search` endpoint | **TL** | Upload file â†’ extract â†’ normalize â†’ query pgvector â†’ return top-5 | Tuáº§n 7 |
| `GET /api/instruments` endpoint | **TL** | List all instruments, with count per type | Tuáº§n 7 |
| `GET /api/instruments/{id}` | **TL** | Detail view: metadata + features + audio URL | Tuáº§n 7 |
| Visualization service | **AE** | `visualizer.py`: generate waveform, spectrogram, chromagram images (matplotlib) | Tuáº§n 7-8 |
| `GET /api/visualize/{id}` | **AE** + **TL** | Serve generated visualization images | Tuáº§n 8 |
| API testing (manual + Swagger) | **FQ** | Test táº¥t cáº£ endpoints qua Swagger UI, ghi bug | Tuáº§n 8 |
| Báº¯t Ä‘áº§u code HTML templates | **FQ** | `base.html`, `index.html` (form upload) | Song song tuáº§n 7-8 |

### Search API â€” Code

```python
# app/routers/search.py
from fastapi import APIRouter, UploadFile, File, Depends
from sqlalchemy.orm import Session
import tempfile, os, joblib
import numpy as np

router = APIRouter(prefix="/api", tags=["Search"])

@router.post("/search")
async def search_similar_instruments(
    file: UploadFile = File(...),
    limit: int = 5,
    db: Session = Depends(get_db)
):
    # 1. Save uploaded file temporarily
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        content = await file.read()
        tmp.write(content)
        tmp_path = tmp.name
    
    try:
        # 2. Extract features
        result = extract_features(tmp_path)
        query_vector = result["feature_vector"]
        
        # 3. Normalize báº±ng CÃ™NG scaler Ä‘Ã£ fit trÃªn dataset
        scaler = joblib.load("models/scaler.pkl")
        query_normalized = scaler.transform(query_vector.reshape(1, -1))[0]
        
        # 4. Generate visualizations cho file query
        viz_paths = generate_visualizations(tmp_path, file.filename)
        
        # 5. Query pgvector â€” cosine distance
        vector_str = str(query_normalized.tolist())
        top_results = db.execute(text(f"""
            SELECT i.*, af.embedding <=> '{vector_str}' AS distance
            FROM audio_features af
            JOIN instruments i ON af.instrument_id = i.id
            ORDER BY distance ASC
            LIMIT :limit
        """), {"limit": limit}).fetchall()
        
        # 6. Format response
        return {
            "query": {
                "filename": file.filename,
                "features": result["details"],
                "visualizations": viz_paths,
            },
            "results": [
                {
                    "rank": idx + 1,
                    "instrument_name": row.instrument_name,
                    "file_name": row.file_name,
                    "similarity_percent": round((1 - row.distance / 2) * 100, 2),
                    "distance": round(row.distance, 6),
                    "audio_url": f"/static/audio/{row.file_path}",
                }
                for idx, row in enumerate(top_results)
            ]
        }
    finally:
        os.unlink(tmp_path)
```

### Visualization Service â€” Code

```python
# app/services/visualizer.py
import librosa
import librosa.display
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
import matplotlib.pyplot as plt
import numpy as np
import os, uuid

VIZ_DIR = "static/visualizations"

def generate_visualizations(file_path: str, filename: str) -> dict:
    """Generate waveform, spectrogram, chromagram â†’ save as PNG."""
    y, sr = librosa.load(file_path, sr=22050)
    viz_id = uuid.uuid4().hex[:8]
    os.makedirs(VIZ_DIR, exist_ok=True)
    paths = {}
    
    # 1. Waveform
    fig, ax = plt.subplots(figsize=(10, 3))
    librosa.display.waveshow(y, sr=sr, ax=ax, color='#2ECC71')
    ax.set_title(f'Waveform â€” {filename}', fontsize=12)
    ax.set_xlabel('Time (s)')
    ax.set_ylabel('Amplitude')
    path = f"{VIZ_DIR}/waveform_{viz_id}.png"
    fig.savefig(path, bbox_inches='tight', dpi=100)
    plt.close(fig)
    paths["waveform"] = f"/{path}"
    
    # 2. Mel Spectrogram
    fig, ax = plt.subplots(figsize=(10, 4))
    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)
    S_dB = librosa.power_to_db(S, ref=np.max)
    img = librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', ax=ax, cmap='magma')
    fig.colorbar(img, ax=ax, format='%+2.0f dB')
    ax.set_title(f'Mel Spectrogram â€” {filename}', fontsize=12)
    path = f"{VIZ_DIR}/spectrogram_{viz_id}.png"
    fig.savefig(path, bbox_inches='tight', dpi=100)
    plt.close(fig)
    paths["spectrogram"] = f"/{path}"
    
    # 3. Chromagram
    fig, ax = plt.subplots(figsize=(10, 3))
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    img = librosa.display.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma', ax=ax, cmap='coolwarm')
    fig.colorbar(img, ax=ax)
    ax.set_title(f'Chromagram â€” {filename}', fontsize=12)
    path = f"{VIZ_DIR}/chromagram_{viz_id}.png"
    fig.savefig(path, bbox_inches='tight', dpi=100)
    plt.close(fig)
    paths["chromagram"] = f"/{path}"
    
    return paths
```

**âœ… Checkpoint cuá»‘i Phase 3:**
- [ ] Swagger UI hoáº¡t Ä‘á»™ng táº¡i `http://localhost:8000/docs`
- [ ] Upload file .wav â†’ nháº­n Ä‘Æ°á»£c JSON vá»›i top-5 results + similarity scores
- [ ] Visualization images Ä‘Æ°á»£c generate vÃ  serve Ä‘Ãºng
- [ ] Error handling: file format sai â†’ tráº£ lá»—i 400, khÃ´ng crash server

---

## PHASE 4: WEB UI + Káº¾T QUáº¢ TRUNG GIAN (Tuáº§n 9â€“10) `21/04 â†’ 04/05`

### PhÃ¢n cÃ´ng Phase 4

| Task | Ai | Chi tiáº¿t | Deadline |
|------|----|----------|----------|
| Trang Search (index.html) | **FQ** | Form upload, drag-and-drop, nÃºt search, loading spinner | Tuáº§n 9 |
| Trang Results (results.html) | **FQ** + **TL** | Top-5 cards, audio players, similarity bars, visualizations | Tuáº§n 9-10 |
| Trang Browse (browse.html) | **FQ** | Danh sÃ¡ch 500 files, filter theo nháº¡c cá»¥, pagination | Tuáº§n 10 |
| Intermediate results panel | **AE** | Hiá»ƒn thá»‹: feature vector values, spectrogram comparison (query vs results) | Tuáº§n 10 |
| CSS styling | **FQ** | Dark theme, responsive, Ä‘áº¹p cho demo | Song song |
| Integration testing | Cáº£ 3 | End-to-end: upload â†’ results â†’ play audio â†’ check intermediate | Cuá»‘i tuáº§n 10 |

### UI Mockup â€” Trang káº¿t quáº£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ» String Instrument Sound Search                    [Browse DB] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€ Your Query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ğŸ“ uploaded_guitar.wav        â–¶ [Play]             â”‚    â”‚
â”‚  â”‚ â”Œâ”€Waveformâ”€â”€â”€â”€â”€â”€â” â”Œâ”€Spectrogramâ”€â”€â”€â”€â” â”Œâ”€Chromaâ”€â”€â” â”‚    â”‚
â”‚  â”‚ â”‚ ~~~~~~~~~~~~~ â”‚ â”‚ â–“â–“â–“â–’â–’â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚ â”‚ â– â–¡â– â–¡â– â–  â”‚ â”‚    â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚ Features: MFCC=[..] Centroid=2341Hz ZCR=0.08     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                             â”‚
â”‚  â”â”â” Top 5 Results â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚                                                             â”‚
â”‚  #1  ğŸ¸ Guitar â€” note_C4.wav       Similarity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 94.2% â”‚
â”‚      â–¶ [Play]  [View Features]  [Compare Spectrogram]        â”‚
â”‚                                                             â”‚
â”‚  #2  ğŸ¸ Guitar â€” note_D4.wav       Similarity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 89.1% â”‚
â”‚      â–¶ [Play]  [View Features]  [Compare Spectrogram]        â”‚
â”‚                                                             â”‚
â”‚  #3  ğŸ¸ Guitar â€” note_E4.wav       Similarity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 82.7% â”‚
â”‚      â–¶ [Play]  [View Features]  [Compare Spectrogram]        â”‚
â”‚                                                             â”‚
â”‚  #4  ğŸª• Banjo â€” note_C4.wav        Similarity: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 71.3% â”‚
â”‚      â–¶ [Play]  [View Features]  [Compare Spectrogram]        â”‚
â”‚                                                             â”‚
â”‚  #5  ğŸ» Violin â€” note_C4.wav       Similarity: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 65.8% â”‚
â”‚      â–¶ [Play]  [View Features]  [Compare Spectrogram]        â”‚
â”‚                                                             â”‚
â”‚  â”â”â” Intermediate Processing Steps â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”  â”‚
â”‚  Step 1: Audio loaded (22050Hz, mono, 3.2s)                  â”‚
â”‚  Step 2: Extracted 30-dim feature vector                     â”‚
â”‚  Step 3: Normalized using StandardScaler                     â”‚
â”‚  Step 4: Cosine similarity search in pgvector (500 vectors)  â”‚
â”‚  Step 5: Returned top-5 results sorted by similarity          â”‚
â”‚  Processing time: 1.23 seconds                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âœ… Checkpoint cuá»‘i Phase 4:**
- [ ] Trang web hoáº¡t Ä‘á»™ng end-to-end trÃªn browser
- [ ] Audio player play Ä‘Æ°á»£c cáº£ file query láº«n result files
- [ ] Visualizations hiá»ƒn thá»‹ Ä‘Ãºng (waveform, spectrogram, chromagram)
- [ ] Intermediate results hiá»ƒn thá»‹ rÃµ rÃ ng cÃ¡c bÆ°á»›c xá»­ lÃ½
- [ ] Responsive trÃªn laptop screen (khÃ´ng cáº§n mobile)

---

## PHASE 5: POLISH & DEMO PREP (Tuáº§n 11â€“12) `05/05 â†’ 18/05`

### PhÃ¢n cÃ´ng Phase 5

| Task | Ai | Chi tiáº¿t | Deadline |
|------|----|----------|----------|
| Bug fixing (critical) | **TL** + **AE** | Fix táº¥t cáº£ bugs phÃ¡t hiá»‡n tá»« Phase 4 | Tuáº§n 11 |
| Chuáº©n bá»‹ test files | **AE** | 5-10 files test: 3 trong dataset (khÃ¡c file gá»‘c), 3-5 ngoÃ i dataset (nháº¡c cá»¥ má»›i/chÆ°a cÃ³) | Tuáº§n 11 |
| Viáº¿t ká»‹ch báº£n demo | **FQ** | Script step-by-step: má»Ÿ app â†’ upload â†’ giáº£i thÃ­ch features â†’ chá»‰ káº¿t quáº£ | Tuáº§n 11 |
| Viáº¿t bÃ¡o cÃ¡o | **FQ** + **AE** | SÆ¡ Ä‘á»“ khá»‘i, giáº£i thÃ­ch features, káº¿t quáº£ evaluation | Tuáº§n 11-12 |
| LÃ m slide trÃ¬nh bÃ y | **FQ** | 10-15 slides: giá»›i thiá»‡u, kiáº¿n trÃºc, features, demo, káº¿t luáº­n | Tuáº§n 12 |
| Dry-run demo | Cáº£ 3 | Cháº¡y thá»­ 3 láº§n, Ä‘o thá»i gian, sá»­a script náº¿u cáº§n | Tuáº§n 12 |
| Quay video backup | **TL** | Screen recording toÃ n bá»™ flow demo, 3-5 phÃºt | Cuá»‘i tuáº§n 12 |
| Final `README.md` | **TL** | HÆ°á»›ng dáº«n setup tá»« 0: install deps â†’ init DB â†’ seed data â†’ run server | Cuá»‘i tuáº§n 12 |

### Demo Script gá»£i Ã½ (5 phÃºt)

```
1. [30s] Giá»›i thiá»‡u: "Há»‡ thá»‘ng tÃ¬m kiáº¿m nháº¡c cá»¥ bá»™ dÃ¢y dá»±a trÃªn Ä‘áº·c trÆ°ng Ã¢m thanh"
2. [30s] Má»Ÿ trang Browse: "Há»‡ thá»‘ng hiá»‡n cÃ³ 500+ files, 6 loáº¡i nháº¡c cá»¥"
3. [60s] Upload file guitar â†’ chá»‰ intermediate results: "Há»‡ thá»‘ng extract 30 Ä‘áº·c trÆ°ng"
4. [60s] Chá»‰ top-5 results: "4/5 lÃ  guitar â€” chá»©ng tá» features hoáº¡t Ä‘á»™ng Ä‘Ãºng"
5. [30s] Play audio so sÃ¡nh: query vs result #1
6. [30s] So sÃ¡nh spectrogram: query vs result #1
7. [60s] Upload file NGOÃ€I dataset (nháº¡c cá»¥ chÆ°a cÃ³ - vÃ­ dá»¥ Ä‘Ã n tranh):
         "Há»‡ thá»‘ng váº«n tÃ¬m Ä‘Æ°á»£c files cÃ³ timbre gáº§n nháº¥t"
8. [30s] Giáº£i thÃ­ch ká»¹ thuáº­t: cosine similarity + pgvector
9. [30s] Káº¿t luáº­n + Q&A
```

**âœ… Checkpoint cuá»‘i Phase 5:**
- [ ] Demo cháº¡y mÆ°á»£t < 5 giÃ¢y/query
- [ ] BÃ¡o cÃ¡o + slide hoÃ n chá»‰nh
- [ ] Video backup Ä‘Ã£ quay
- [ ] `README.md` hÆ°á»›ng dáº«n setup hoÃ n chá»‰nh
- [ ] Dry-run PASS 3/3 láº§n

---

# 4. Äá»€ XUáº¤T NÃ‚NG CAO: Audio Embeddings báº±ng Neural Network ğŸ§ 

> [!NOTE]
> **ÄÃ¢y lÃ  hÆ°á»›ng nÃ¢ng cao.** Chá»‰ lÃ m náº¿u nhÃ³m hoÃ n thÃ nh MVP sá»›m (trÆ°á»›c tuáº§n 10). KhÃ´ng áº£nh hÆ°á»Ÿng Ä‘iá»ƒm náº¿u khÃ´ng lÃ m, nhÆ°ng sáº½ gÃ¢y áº¥n tÆ°á»£ng máº¡nh náº¿u demo Ä‘Æ°á»£c.

### Ã tÆ°á»Ÿng

Thay vÃ¬ dÃ¹ng hand-crafted features (MFCC, Chroma...), sá»­ dá»¥ng **pre-trained neural network** Ä‘á»ƒ táº¡o embedding tá»± Ä‘á»™ng:

| Approach | MVP (Äang lÃ m) | NÃ¢ng cao |
|----------|----------------|----------|
| Feature extraction | Thá»§ cÃ´ng: MFCC + Chroma + Spectral â†’ 30-dim | Model pre-trained: audio â†’ 128/512-dim embedding tá»± Ä‘á»™ng |
| ThÆ° viá»‡n | `librosa` | `openl3`, `panns-inference`, hoáº·c `CLAP` |
| Æ¯u Ä‘iá»ƒm | Dá»… hiá»ƒu, giáº£i thÃ­ch Ä‘Æ°á»£c tá»«ng feature | Cháº¥t lÆ°á»£ng similarity cao hÆ¡n, báº¯t Ä‘Æ°á»£c patterns phá»©c táº¡p |
| NhÆ°á»£c Ä‘iá»ƒm | Bá» sÃ³t thÃ´ng tin mÃ  hand-craft khÃ´ng capture | "Black box", khÃ³ giáº£i thÃ­ch cho giáº£ng viÃªn |

### CÃ´ng cá»¥ gá»£i Ã½

- **OpenL3** (`openl3` pip package) â€” Facebook Research, táº¡o audio embedding 512-dim, cá»±c dá»… dÃ¹ng:
  ```python
  import openl3
  import soundfile as sf
  audio, sr = sf.read("guitar.wav")
  embedding, ts = openl3.get_audio_embedding(audio, sr, content_type="music")
  # embedding shape: (N_frames, 512) â†’ láº¥y mean â†’ (512,)
  ```
- **PANNs** (Pretrained Audio Neural Networks) â€” Google, classify 527 audio events
- **CLAP** (Contrastive Language-Audio Pretraining) â€” Microsoft, search audio báº±ng text query

### CÃ¡ch tÃ­ch há»£p (náº¿u lÃ m)

ThÃªm 1 cá»™t `embedding_nn vector(512)` vÃ o báº£ng `audio_features`, cháº¡y song song vá»›i `embedding` 30-dim hiá»‡n táº¡i. UI cho phÃ©p chá»n "Search by: [Traditional Features] [Neural Embedding]" â†’ so sÃ¡nh káº¿t quáº£.

**Äiá»u nÃ y táº¡o cÃ¢u chuyá»‡n ráº¥t hay cho báº£o vá»‡:** *"ChÃºng em Ä‘Ã£ implement cáº£ 2 approach â€” traditional feature engineering VÃ€ neural embedding â€” vÃ  so sÃ¡nh cháº¥t lÆ°á»£ng. Neural embedding cho káº¿t quáº£ tá»‘t hÆ¡n X% nhÆ°ng khÃ³ giáº£i thÃ­ch hÆ¡n."*

---

# 5. COMMUNICATION & WORKFLOW

### Weekly Standup (má»—i Chá»§ Nháº­t tá»‘i, 15 phÃºt)

```
Má»—i ngÆ°á»i tráº£ lá»i 3 cÃ¢u:
1. Tuáº§n nÃ y lÃ m Ä‘Æ°á»£c gÃ¬?
2. Tuáº§n sau sáº½ lÃ m gÃ¬?
3. Äang stuck á»Ÿ Ä‘Ã¢u? (náº¿u cÃ³)
```

### Tools

| Má»¥c Ä‘Ã­ch | Tool | LÃ½ do |
|----------|------|-------|
| Quáº£n lÃ½ task | Trello / Notion (free) | Kanban board, má»—i task cÃ³ assignee + deadline |
| Code | GitHub (free) | Version control, pull requests |
| Chat nhÃ³m | Zalo / Discord | Realtime communication |
| Demo video | OBS Studio (free) | Quay video backup |

### Git Workflow (Ä‘Æ¡n giáº£n)

```
main â† Chá»‰ merge code Ä‘Ã£ test
  â†‘
  feature/xxx â† Má»—i ngÆ°á»i code trÃªn branch riÃªng
```

KhÃ´ng cáº§n PR review formal â€” merge khi Ä‘Ã£ cháº¡y Ä‘Æ°á»£c local, conflict thÃ¬ giáº£i quyáº¿t qua call.

---

# 6. Tá»”NG Káº¾T PHÃ‚N CÃ”NG THEO TUáº¦N

| Tuáº§n | TL (Tech Lead) | AE (Audio Engineer) | FQ (Frontend + QA) |
|------|----------------|--------------------|--------------------|
| 1 | Setup repo, PostgreSQL, pgvector | CÃ i Python, tutorial librosa | CÃ i mÃ´i trÆ°á»ng |
| 2 | Tutorial FastAPI, test pgvector | Tutorial librosa + extract MFCC | Tutorial Jinja2 + HTML form |
| 3 | â€” | Download + filter NSynth | Download IRMAS + Freesound |
| 4 | Validate data script | Normalize audio script + metadata.csv | Bá»• sung data tá»« Freesound |
| 5 | DB schema + ORM models | **Feature extractor (pair vá»›i TL)** | Wireframe UI mockup |
| 6 | **Seed script (pair vá»›i AE)** | Unit test features + sanity check | Wireframe + báº¯t Ä‘áº§u HTML |
| 7 | Search API endpoints | Visualization service | Test API qua Swagger + HTML template |
| 8 | API error handling + polish | Visualize endpoint + test | Trang Upload hoÃ n chá»‰nh |
| 9 | Integration: API â†” UI | Intermediate results panel | Trang Results + CSS styling |
| 10 | Integration testing | Compare spectrogram feature | Trang Browse + final CSS |
| 11 | Bug fixing | Chuáº©n bá»‹ test files + evaluation | BÃ¡o cÃ¡o + slide |
| 12 | README + video backup + dry-run | Dry-run + há»— trá»£ bÃ¡o cÃ¡o | Demo script + dry-run |
